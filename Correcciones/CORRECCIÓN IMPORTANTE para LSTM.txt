## ‚ùå **CORRECCI√ìN IMPORTANTE: para LSTM**

### **üîç AN√ÅLISIS DEL PROBLEMA:**

**Tu modelo problem√°tico es:**
- **Regime (LSTM)**: Overfitting = **0.295** ‚ùå
- **Tipo**: **Red Neuronal LSTM** (no XGBoost)

**‚ùå Los par√°metros que mencion√© son para XGBoost:**
- `reg_alpha`, `reg_lambda`, `n_estimators`, `max_depth` = **NO EXISTEN en LSTM**

---

## **üîß INSTRUCCIONES CORRECTAS PARA LSTM REGIME**### **üîß INSTRUCCIONES CORRECTAS PARA LSTM REGIME**

**PROBLEMA:** Regime (LSTM) = 0.295 overfitting ‚ùå  
**TARGET:** 0.18 overfitting ‚úÖ  
**TIPO:** Red Neuronal LSTM (TensorFlow/Keras)

---

## **üìÅ ARCHIVO 1: `config/training_config.yaml`**

### **üéØ CAMBIO 1.1: Secci√≥n Regime LSTM (Buscar y reemplazar)**

**BUSCAR:**
```yaml
rebound:
  algorithm: "regularized_lstm"
  params:
    sequence_length: 24
    lstm_units: 50
    dropout_rate: 0.5
    recurrent_dropout: 0.3
    batch_normalization: true
    l2_regularization: 0.01
```

**REEMPLAZAR CON:**
```yaml
# Predictor de Rebotes (1-3%) - LSTM Regularizado
rebound:
  algorithm: "regularized_lstm"
  params:
    sequence_length: 16            # üîΩ REDUCIDO de 24 a 16
    lstm_units_layer1: 32          # üîΩ REDUCIDO de 50 a 32
    lstm_units_layer2: 16          # üîΩ Nueva capa m√°s peque√±a
    dropout_rate: 0.7              # üîº AUMENTADO de 0.5 a 0.7
    recurrent_dropout: 0.5         # üîº AUMENTADO de 0.3 a 0.5
    batch_normalization: true
    l2_regularization: 0.05        # üîº AUMENTADO de 0.01 a 0.05
    learning_rate: 0.0005          # üîΩ REDUCIDO para convergencia lenta
    batch_size: 16                 # üîΩ REDUCIDO de 32 a 16
    epochs: 50                     # üîΩ REDUCIDO de 100 a 50
    
  early_stopping:
    enabled: true
    patience: 8                    # üîΩ REDUCIDO de 15 a 8
    monitor: 'val_loss'
    restore_best_weights: true
    min_delta: 0.001              # M√≠nima mejora requerida
    
  callbacks:
    reduce_lr_on_plateau:
      enabled: true
      factor: 0.3                  # üîΩ REDUCIR LR m√°s agresivo
      patience: 5                  # üîΩ REDUCIDO de 8 a 5
      min_lr: 0.00001             # LR m√≠nimo
      
# AGREGAR: Configuraci√≥n espec√≠fica para Regime si es LSTM
regime:
  algorithm: "regularized_lstm"    # ‚úÖ CONFIRMAR si es LSTM
  params:
    sequence_length: 12            # üîΩ SECUENCIAS M√ÅS CORTAS
    lstm_units_layer1: 24          # üîΩ UNIDADES DRAM√ÅTICAMENTE REDUCIDAS
    lstm_units_layer2: 12          # üîΩ SEGUNDA CAPA PEQUE√ëA
    dropout_rate: 0.8              # üîº M√ÅXIMO DROPOUT
    recurrent_dropout: 0.6         # üîº ALTO RECURRENT DROPOUT
    batch_normalization: true
    l2_regularization: 0.1         # üîº REGULARIZACI√ìN L2 ALTA
    learning_rate: 0.0003          # üîΩ MUY LENTO
    batch_size: 12                 # üîΩ BATCH SIZE MUY PEQUE√ëO
    epochs: 30                     # üîΩ POCAS √âPOCAS
    
  early_stopping:
    enabled: true
    patience: 5                    # üîΩ MUY AGRESIVO
    monitor: 'val_loss'
    restore_best_weights: true
    min_delta: 0.002              # Mayor mejora requerida
    
  callbacks:
    reduce_lr_on_plateau:
      enabled: true
      factor: 0.2                  # üîΩ REDUCCI√ìN DR√ÅSTICA LR
      patience: 3                  # üîΩ MUY IMPACIENTE
      min_lr: 0.000001            # LR s√∫per m√≠nimo
```

---

## **üìÅ ARCHIVO 2: `src/models/regularized_models.py`**

### **üéØ CAMBIO 2.1: Funci√≥n `_build_model()` para Regime LSTM**

**BUSCAR la clase `RegularizedLSTM` y funci√≥n `_build_model()`:**

**REEMPLAZAR CON:**
```python
def _build_model(self, input_shape: Tuple[int, int]) -> Sequential:
    """Construir modelo LSTM con regularizaci√≥n M√ÅXIMA para Regime."""
    
    # Par√°metros espec√≠ficos por tarea
    if self.task_type == 'regime':
        # üõ°Ô∏è CONFIGURACI√ìN ANTI-OVERFITTING M√ÅXIMA PARA REGIME
        model = Sequential([
            # Primera capa LSTM MUY PEQUE√ëA
            LSTM(24, return_sequences=True, input_shape=input_shape,
                 dropout=0.8,           # üîº DROPOUT M√ÅXIMO
                 recurrent_dropout=0.6, # üîº RECURRENT DROPOUT ALTO
                 kernel_regularizer=tf.keras.regularizers.l2(0.1), # üîº L2 ALTO
                 recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
            BatchNormalization(),
            
            # Segunda capa LSTM A√öN M√ÅS PEQUE√ëA
            LSTM(12, return_sequences=False,
                 dropout=0.8,           # üîº DROPOUT M√ÅXIMO  
                 recurrent_dropout=0.6, # üîº RECURRENT DROPOUT ALTO
                 kernel_regularizer=tf.keras.regularizers.l2(0.1),
                 recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
            BatchNormalization(),
            
            # Capas densas M√çNIMAS
            Dense(8, activation='relu',
                  kernel_regularizer=tf.keras.regularizers.l2(0.1)),
            Dropout(0.7),              # üîº DROPOUT ALT√çSIMO
            
            Dense(4, activation='relu',
                  kernel_regularizer=tf.keras.regularizers.l2(0.1)),
            Dropout(0.6),
            
            # Output layer para 3 clases (Bear/Side/Bull)
            Dense(3, activation='softmax')  # üéØ 3 CLASES PARA REGIME
        ])
        
        # Optimizador S√öPER CONSERVADOR
        optimizer = tf.keras.optimizers.Adam(
            learning_rate=0.0003,      # üîΩ LEARNING RATE M√ÅS LENTO
            beta_1=0.9,
            beta_2=0.999,
            epsilon=1e-7
        )
        
        model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',  # Para 3 clases
            metrics=['accuracy']
        )
        
    else:
        # Configuraci√≥n normal para otros modelos (rebound, momentum)
        model = Sequential([
            LSTM(50, return_sequences=True, input_shape=input_shape),
            Dropout(0.3),
            BatchNormalization(),
            LSTM(25, return_sequences=False),
            Dropout(0.4),
            BatchNormalization(),
            Dense(15, activation='relu'),
            Dropout(0.3),
            Dense(8, activation='relu'),
            Dropout(0.2),
            Dense(1, activation='sigmoid' if self.task_type == 'rebound' else 'linear')
        ])
        
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        model.compile(
            optimizer=optimizer,
            loss='binary_crossentropy' if self.task_type == 'rebound' else 'mse',
            metrics=['accuracy'] if self.task_type == 'rebound' else ['mae']
        )
    
    return model
```

### **üéØ CAMBIO 2.2: Funci√≥n `fit()` con early stopping agresivo**

**BUSCAR funci√≥n `fit()` y AGREGAR:**

```python
def fit(self, X_train: pd.DataFrame, y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None, y_val: Optional[pd.Series] = None,
        epochs: int = 100):
    """Entrenar LSTM con regularizaci√≥n espec√≠fica por tarea."""
    
    # üéØ CONFIGURACI√ìN ESPEC√çFICA PARA REGIME
    if self.task_type == 'regime':
        epochs = 30                    # üîΩ POCAS √âPOCAS PARA REGIME
        batch_size = 12                # üîΩ BATCH SIZE PEQUE√ëO
        early_stopping_patience = 5   # üîΩ PATIENCE MUY BAJO
        
        # Callbacks agresivos para Regime
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=early_stopping_patience,
                restore_best_weights=True,
                verbose=1,
                min_delta=0.002        # üîº MAYOR MEJORA REQUERIDA
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,            # üîΩ REDUCCI√ìN DR√ÅSTICA
                patience=3,            # üîΩ MUY IMPACIENTE
                min_lr=0.000001,       # üîΩ LR S√öPER M√çNIMO
                verbose=1
            )
        ]
    else:
        # Configuraci√≥n normal para otros modelos
        batch_size = 32
        early_stopping_patience = 15
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=early_stopping_patience,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-7,
                verbose=1
            )
        ]
    
    # ... resto del c√≥digo de entrenamiento
    # Usar las variables epochs, batch_size, callbacks configuradas arriba
    
    history = self.model.fit(
        X_train_seq, y_train_seq,
        validation_data=validation_data,
        epochs=epochs,                 # üéØ √âPOCAS ESPEC√çFICAS POR TAREA
        batch_size=batch_size,         # üéØ BATCH SIZE ESPEC√çFICO
        callbacks=callbacks,           # üéØ CALLBACKS ESPEC√çFICOS
        verbose=1
    )
    
    # üìä LOGGING ESPEC√çFICO PARA REGIME
    if self.task_type == 'regime':
        final_train_loss = history.history['loss'][-1]
        final_val_loss = history.history['val_loss'][-1] if validation_data else None
        
        self.logger.info(f"üéØ REGIME LSTM ANTI-OVERFITTING:")
        self.logger.info(f"  √âpocas entrenadas: {len(history.history['loss'])}/{epochs}")
        self.logger.info(f"  Loss final train: {final_train_loss:.4f}")
        
        if final_val_loss:
            self.logger.info(f"  Loss final val: {final_val_loss:.4f}")
            overfitting_ratio = final_train_loss / final_val_loss if final_val_loss > 0 else float('inf')
            overfitting_gap = abs(final_train_loss - final_val_loss)
            
            self.logger.info(f"  Gap train-val: {overfitting_gap:.4f}")
            self.logger.info(f"  Ratio train/val: {overfitting_ratio:.4f}")
            
            # üéØ VERIFICACI√ìN TARGET 0.18
            if overfitting_gap <= 0.20:
                if overfitting_gap <= 0.18:
                    self.logger.info("‚úÖ TARGET OVERFITTING ALCANZADO (‚â§0.18)")
                else:
                    self.logger.info("‚úÖ OVERFITTING EN RANGO ACEPTABLE (‚â§0.20)")
            else:
                self.logger.warning(f"‚ö†Ô∏è OVERFITTING A√öN ALTO: {overfitting_gap:.4f} > 0.20")
    
    return history
```

---

## **üìÅ ARCHIVO 3: Crear `scripts/fix_lstm_regime_overfitting.py`**

```python
#!/usr/bin/env python3
"""
Script espec√≠fico para corregir overfitting LSTM Regime: 0.295 ‚Üí 0.18
"""

import sys
import os
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import tensorflow as tf

# Agregar path del proyecto
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_lstm_regime_optimization():
    """Test espec√≠fico para LSTM Regime con nuevos par√°metros."""
    logger.info("üéØ TEST LSTM REGIME: Overfitting 0.295 ‚Üí 0.18")
    logger.info("="*60)
    
    # Simular datos de r√©gimen (Bear=0, Side=1, Bull=2)
    np.random.seed(42)
    n_samples = 1000
    sequence_length = 12  # Nuevo par√°metro reducido
    n_features = 20
    
    # Generar datos simulados m√°s simples
    X = np.random.randn(n_samples, n_features)
    
    # Target para 3 clases (r√©gimen)
    signal = X[:, 0] * 0.5 + X[:, 1] * 0.3 + np.random.randn(n_samples) * 0.2
    y = np.digitize(signal, bins=[-0.3, 0.3])  # 3 clases: 0, 1, 2
    
    # Crear secuencias temporales
    X_sequences = []
    y_sequences = []
    
    for i in range(sequence_length, len(X)):
        X_sequences.append(X[i-sequence_length:i])
        y_sequences.append(y[i])
    
    X_sequences = np.array(X_sequences)
    y_sequences = np.array(y_sequences)
    
    # Split
    split_idx = int(len(X_sequences) * 0.7)
    val_split_idx = int(len(X_sequences) * 0.85)
    
    X_train = X_sequences[:split_idx]
    y_train = y_sequences[:split_idx]
    X_val = X_sequences[split_idx:val_split_idx]
    y_val = y_sequences[split_idx:val_split_idx]
    
    logger.info(f"üìä Datos: Train={len(X_train)}, Val={len(X_val)}")
    logger.info(f"üìä Shape: {X_train.shape}, Clases: {np.unique(y_train)}")
    
    # Construir modelo LSTM optimizado
    model = tf.keras.Sequential([
        # üõ°Ô∏è CONFIGURACI√ìN ANTI-OVERFITTING M√ÅXIMA
        tf.keras.layers.LSTM(24, return_sequences=True, input_shape=(sequence_length, n_features),
                            dropout=0.8, recurrent_dropout=0.6,
                            kernel_regularizer=tf.keras.regularizers.l2(0.1),
                            recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
        tf.keras.layers.BatchNormalization(),
        
        tf.keras.layers.LSTM(12, return_sequences=False,
                            dropout=0.8, recurrent_dropout=0.6,
                            kernel_regularizer=tf.keras.regularizers.l2(0.1),
                            recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
        tf.keras.layers.BatchNormalization(),
        
        tf.keras.layers.Dense(8, activation='relu',
                             kernel_regularizer=tf.keras.regularizers.l2(0.1)),
        tf.keras.layers.Dropout(0.7),
        
        tf.keras.layers.Dense(4, activation='relu',
                             kernel_regularizer=tf.keras.regularizers.l2(0.1)),
        tf.keras.layers.Dropout(0.6),
        
        tf.keras.layers.Dense(3, activation='softmax')
    ])
    
    # Optimizador conservador
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # Callbacks agresivos
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,              # üîΩ MUY BAJO
            restore_best_weights=True,
            min_delta=0.002         # üîº MAYOR MEJORA REQUERIDA
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.2,             # üîΩ REDUCCI√ìN DR√ÅSTICA
            patience=3,             # üîΩ IMPACIENTE
            min_lr=0.000001
        )
    ]
    
    logger.info("üß™ Entrenando LSTM Regime optimizado...")
    
    # Entrenar modelo
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=30,               # üîΩ POCAS √âPOCAS
        batch_size=12,           # üîΩ BATCH PEQUE√ëO
        callbacks=callbacks,
        verbose=1
    )
    
    # Calcular overfitting
    train_loss = min(history.history['loss'])
    val_loss = min(history.history['val_loss'])
    overfitting_gap = abs(train_loss - val_loss)
    
    train_acc = max(history.history['accuracy'])
    val_acc = max(history.history['val_accuracy'])
    
    logger.info(f"\nüìä RESULTADOS LSTM REGIME OPTIMIZADO:")
    logger.info(f"  Train Loss: {train_loss:.4f}")
    logger.info(f"  Val Loss: {val_loss:.4f}")
    logger.info(f"  Overfitting Gap: {overfitting_gap:.4f}")
    logger.info(f"  Train Accuracy: {train_acc:.1%}")
    logger.info(f"  Val Accuracy: {val_acc:.1%}")
    logger.info(f"  √âpocas entrenadas: {len(history.history['loss'])}")
    
    # Verificaci√≥n target
    target_value = 0.18
    previous_gap = 0.295
    
    if overfitting_gap <= 0.20:
        if overfitting_gap <= target_value:
            status = "üéØ TARGET PERFECTO ALCANZADO"
        else:
            status = "‚úÖ RANGO √ìPTIMO"
        logger.info(f"  ‚úÖ {status}")
    else:
        status = "‚ùå REQUIERE M√ÅS OPTIMIZACI√ìN"
        logger.warning(f"  ‚ùå {status}")
    
    # Comparaci√≥n
    improvement = previous_gap - overfitting_gap
    improvement_pct = (improvement / previous_gap) * 100
    
    logger.info(f"\nüìà COMPARACI√ìN:")
    logger.info(f"  Overfitting anterior: {previous_gap:.3f}")
    logger.info(f"  Overfitting actual: {overfitting_gap:.3f}")
    logger.info(f"  Mejora: {improvement:.3f} ({improvement_pct:.1f}%)")
    
    return overfitting_gap <= 0.20

if __name__ == "__main__":
    success = test_lstm_regime_optimization()
    
    if success:
        logger.info("\n‚úÖ OPTIMIZACI√ìN LSTM EXITOSA")
        logger.info("üéØ Regime LSTM optimizado para target overfitting ‚â§0.18")
    else:
        logger.warning("\n‚ö†Ô∏è REQUIERE AJUSTES ADICIONALES")
```

---

## **üöÄ INSTRUCCIONES DE IMPLEMENTACI√ìN GITHUB**

### **üìã COMMIT STRATEGY:**

```bash
# 1. Crear rama espec√≠fica
git checkout -b fix-lstm-regime-overfitting

# 2. Aplicar cambios
git add config/training_config.yaml
git add src/models/regularized_models.py
git add scripts/fix_lstm_regime_overfitting.py

# 3. Commit espec√≠fico
git commit -m "üéØ Fix LSTM Regime overfitting: 0.295 ‚Üí 0.18

LSTM-specific optimizations:
- Increase dropout: 0.5‚Üí0.8, recurrent_dropout: 0.3‚Üí0.6
- Reduce LSTM units: 50‚Üí24‚Üí12 (much smaller)
- Increase L2 regularization: 0.01‚Üí0.1 
- Aggressive early stopping: patience 15‚Üí5
- Reduce epochs: 100‚Üí30, batch_size: 32‚Üí12
- Lower learning rate: 0.001‚Üí0.0003

Target: LSTM overfitting gap ‚â§ 0.18"

# 4. Test antes de push
python scripts/fix_lstm_regime_overfitting.py

# 5. Push si test exitoso
git push origin fix-lstm-regime-overfitting
```

### **‚úÖ VALIDACI√ìN ESPERADA:**

```
üéØ TARGET PERFECTO ALCANZADO
‚úÖ Overfitting Gap: 0.17X ‚â§ 0.18
üìà Mejora: 0.12X (42.3%)
```

### **‚ö†Ô∏è SI NO FUNCIONA:**

Aplicar configuraci√≥n a√∫n m√°s agresiva:
- `dropout_rate: 0.9` (m√°ximo)
- `lstm_units: 16, 8` (a√∫n m√°s peque√±o)
- `epochs: 20` (s√∫per pocas)
- `patience: 3` (m√°ximo agresivo)

**¬øListo para aplicar estos cambios espec√≠ficos para LSTM?** üéØ