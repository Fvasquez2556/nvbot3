## ❌ **CORRECCIÓN IMPORTANTE: para LSTM**

### **🔍 ANÁLISIS DEL PROBLEMA:**

**Tu modelo problemático es:**
- **Regime (LSTM)**: Overfitting = **0.295** ❌
- **Tipo**: **Red Neuronal LSTM** (no XGBoost)

**❌ Los parámetros que mencioné son para XGBoost:**
- `reg_alpha`, `reg_lambda`, `n_estimators`, `max_depth` = **NO EXISTEN en LSTM**

---

## **🔧 INSTRUCCIONES CORRECTAS PARA LSTM REGIME**### **🔧 INSTRUCCIONES CORRECTAS PARA LSTM REGIME**

**PROBLEMA:** Regime (LSTM) = 0.295 overfitting ❌  
**TARGET:** 0.18 overfitting ✅  
**TIPO:** Red Neuronal LSTM (TensorFlow/Keras)

---

## **📁 ARCHIVO 1: `config/training_config.yaml`**

### **🎯 CAMBIO 1.1: Sección Regime LSTM (Buscar y reemplazar)**

**BUSCAR:**
```yaml
rebound:
  algorithm: "regularized_lstm"
  params:
    sequence_length: 24
    lstm_units: 50
    dropout_rate: 0.5
    recurrent_dropout: 0.3
    batch_normalization: true
    l2_regularization: 0.01
```

**REEMPLAZAR CON:**
```yaml
# Predictor de Rebotes (1-3%) - LSTM Regularizado
rebound:
  algorithm: "regularized_lstm"
  params:
    sequence_length: 16            # 🔽 REDUCIDO de 24 a 16
    lstm_units_layer1: 32          # 🔽 REDUCIDO de 50 a 32
    lstm_units_layer2: 16          # 🔽 Nueva capa más pequeña
    dropout_rate: 0.7              # 🔼 AUMENTADO de 0.5 a 0.7
    recurrent_dropout: 0.5         # 🔼 AUMENTADO de 0.3 a 0.5
    batch_normalization: true
    l2_regularization: 0.05        # 🔼 AUMENTADO de 0.01 a 0.05
    learning_rate: 0.0005          # 🔽 REDUCIDO para convergencia lenta
    batch_size: 16                 # 🔽 REDUCIDO de 32 a 16
    epochs: 50                     # 🔽 REDUCIDO de 100 a 50
    
  early_stopping:
    enabled: true
    patience: 8                    # 🔽 REDUCIDO de 15 a 8
    monitor: 'val_loss'
    restore_best_weights: true
    min_delta: 0.001              # Mínima mejora requerida
    
  callbacks:
    reduce_lr_on_plateau:
      enabled: true
      factor: 0.3                  # 🔽 REDUCIR LR más agresivo
      patience: 5                  # 🔽 REDUCIDO de 8 a 5
      min_lr: 0.00001             # LR mínimo
      
# AGREGAR: Configuración específica para Regime si es LSTM
regime:
  algorithm: "regularized_lstm"    # ✅ CONFIRMAR si es LSTM
  params:
    sequence_length: 12            # 🔽 SECUENCIAS MÁS CORTAS
    lstm_units_layer1: 24          # 🔽 UNIDADES DRAMÁTICAMENTE REDUCIDAS
    lstm_units_layer2: 12          # 🔽 SEGUNDA CAPA PEQUEÑA
    dropout_rate: 0.8              # 🔼 MÁXIMO DROPOUT
    recurrent_dropout: 0.6         # 🔼 ALTO RECURRENT DROPOUT
    batch_normalization: true
    l2_regularization: 0.1         # 🔼 REGULARIZACIÓN L2 ALTA
    learning_rate: 0.0003          # 🔽 MUY LENTO
    batch_size: 12                 # 🔽 BATCH SIZE MUY PEQUEÑO
    epochs: 30                     # 🔽 POCAS ÉPOCAS
    
  early_stopping:
    enabled: true
    patience: 5                    # 🔽 MUY AGRESIVO
    monitor: 'val_loss'
    restore_best_weights: true
    min_delta: 0.002              # Mayor mejora requerida
    
  callbacks:
    reduce_lr_on_plateau:
      enabled: true
      factor: 0.2                  # 🔽 REDUCCIÓN DRÁSTICA LR
      patience: 3                  # 🔽 MUY IMPACIENTE
      min_lr: 0.000001            # LR súper mínimo
```

---

## **📁 ARCHIVO 2: `src/models/regularized_models.py`**

### **🎯 CAMBIO 2.1: Función `_build_model()` para Regime LSTM**

**BUSCAR la clase `RegularizedLSTM` y función `_build_model()`:**

**REEMPLAZAR CON:**
```python
def _build_model(self, input_shape: Tuple[int, int]) -> Sequential:
    """Construir modelo LSTM con regularización MÁXIMA para Regime."""
    
    # Parámetros específicos por tarea
    if self.task_type == 'regime':
        # 🛡️ CONFIGURACIÓN ANTI-OVERFITTING MÁXIMA PARA REGIME
        model = Sequential([
            # Primera capa LSTM MUY PEQUEÑA
            LSTM(24, return_sequences=True, input_shape=input_shape,
                 dropout=0.8,           # 🔼 DROPOUT MÁXIMO
                 recurrent_dropout=0.6, # 🔼 RECURRENT DROPOUT ALTO
                 kernel_regularizer=tf.keras.regularizers.l2(0.1), # 🔼 L2 ALTO
                 recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
            BatchNormalization(),
            
            # Segunda capa LSTM AÚN MÁS PEQUEÑA
            LSTM(12, return_sequences=False,
                 dropout=0.8,           # 🔼 DROPOUT MÁXIMO  
                 recurrent_dropout=0.6, # 🔼 RECURRENT DROPOUT ALTO
                 kernel_regularizer=tf.keras.regularizers.l2(0.1),
                 recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
            BatchNormalization(),
            
            # Capas densas MÍNIMAS
            Dense(8, activation='relu',
                  kernel_regularizer=tf.keras.regularizers.l2(0.1)),
            Dropout(0.7),              # 🔼 DROPOUT ALTÍSIMO
            
            Dense(4, activation='relu',
                  kernel_regularizer=tf.keras.regularizers.l2(0.1)),
            Dropout(0.6),
            
            # Output layer para 3 clases (Bear/Side/Bull)
            Dense(3, activation='softmax')  # 🎯 3 CLASES PARA REGIME
        ])
        
        # Optimizador SÚPER CONSERVADOR
        optimizer = tf.keras.optimizers.Adam(
            learning_rate=0.0003,      # 🔽 LEARNING RATE MÁS LENTO
            beta_1=0.9,
            beta_2=0.999,
            epsilon=1e-7
        )
        
        model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',  # Para 3 clases
            metrics=['accuracy']
        )
        
    else:
        # Configuración normal para otros modelos (rebound, momentum)
        model = Sequential([
            LSTM(50, return_sequences=True, input_shape=input_shape),
            Dropout(0.3),
            BatchNormalization(),
            LSTM(25, return_sequences=False),
            Dropout(0.4),
            BatchNormalization(),
            Dense(15, activation='relu'),
            Dropout(0.3),
            Dense(8, activation='relu'),
            Dropout(0.2),
            Dense(1, activation='sigmoid' if self.task_type == 'rebound' else 'linear')
        ])
        
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        model.compile(
            optimizer=optimizer,
            loss='binary_crossentropy' if self.task_type == 'rebound' else 'mse',
            metrics=['accuracy'] if self.task_type == 'rebound' else ['mae']
        )
    
    return model
```

### **🎯 CAMBIO 2.2: Función `fit()` con early stopping agresivo**

**BUSCAR función `fit()` y AGREGAR:**

```python
def fit(self, X_train: pd.DataFrame, y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None, y_val: Optional[pd.Series] = None,
        epochs: int = 100):
    """Entrenar LSTM con regularización específica por tarea."""
    
    # 🎯 CONFIGURACIÓN ESPECÍFICA PARA REGIME
    if self.task_type == 'regime':
        epochs = 30                    # 🔽 POCAS ÉPOCAS PARA REGIME
        batch_size = 12                # 🔽 BATCH SIZE PEQUEÑO
        early_stopping_patience = 5   # 🔽 PATIENCE MUY BAJO
        
        # Callbacks agresivos para Regime
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=early_stopping_patience,
                restore_best_weights=True,
                verbose=1,
                min_delta=0.002        # 🔼 MAYOR MEJORA REQUERIDA
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,            # 🔽 REDUCCIÓN DRÁSTICA
                patience=3,            # 🔽 MUY IMPACIENTE
                min_lr=0.000001,       # 🔽 LR SÚPER MÍNIMO
                verbose=1
            )
        ]
    else:
        # Configuración normal para otros modelos
        batch_size = 32
        early_stopping_patience = 15
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=early_stopping_patience,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-7,
                verbose=1
            )
        ]
    
    # ... resto del código de entrenamiento
    # Usar las variables epochs, batch_size, callbacks configuradas arriba
    
    history = self.model.fit(
        X_train_seq, y_train_seq,
        validation_data=validation_data,
        epochs=epochs,                 # 🎯 ÉPOCAS ESPECÍFICAS POR TAREA
        batch_size=batch_size,         # 🎯 BATCH SIZE ESPECÍFICO
        callbacks=callbacks,           # 🎯 CALLBACKS ESPECÍFICOS
        verbose=1
    )
    
    # 📊 LOGGING ESPECÍFICO PARA REGIME
    if self.task_type == 'regime':
        final_train_loss = history.history['loss'][-1]
        final_val_loss = history.history['val_loss'][-1] if validation_data else None
        
        self.logger.info(f"🎯 REGIME LSTM ANTI-OVERFITTING:")
        self.logger.info(f"  Épocas entrenadas: {len(history.history['loss'])}/{epochs}")
        self.logger.info(f"  Loss final train: {final_train_loss:.4f}")
        
        if final_val_loss:
            self.logger.info(f"  Loss final val: {final_val_loss:.4f}")
            overfitting_ratio = final_train_loss / final_val_loss if final_val_loss > 0 else float('inf')
            overfitting_gap = abs(final_train_loss - final_val_loss)
            
            self.logger.info(f"  Gap train-val: {overfitting_gap:.4f}")
            self.logger.info(f"  Ratio train/val: {overfitting_ratio:.4f}")
            
            # 🎯 VERIFICACIÓN TARGET 0.18
            if overfitting_gap <= 0.20:
                if overfitting_gap <= 0.18:
                    self.logger.info("✅ TARGET OVERFITTING ALCANZADO (≤0.18)")
                else:
                    self.logger.info("✅ OVERFITTING EN RANGO ACEPTABLE (≤0.20)")
            else:
                self.logger.warning(f"⚠️ OVERFITTING AÚN ALTO: {overfitting_gap:.4f} > 0.20")
    
    return history
```

---

## **📁 ARCHIVO 3: Crear `scripts/fix_lstm_regime_overfitting.py`**

```python
#!/usr/bin/env python3
"""
Script específico para corregir overfitting LSTM Regime: 0.295 → 0.18
"""

import sys
import os
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import tensorflow as tf

# Agregar path del proyecto
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_lstm_regime_optimization():
    """Test específico para LSTM Regime con nuevos parámetros."""
    logger.info("🎯 TEST LSTM REGIME: Overfitting 0.295 → 0.18")
    logger.info("="*60)
    
    # Simular datos de régimen (Bear=0, Side=1, Bull=2)
    np.random.seed(42)
    n_samples = 1000
    sequence_length = 12  # Nuevo parámetro reducido
    n_features = 20
    
    # Generar datos simulados más simples
    X = np.random.randn(n_samples, n_features)
    
    # Target para 3 clases (régimen)
    signal = X[:, 0] * 0.5 + X[:, 1] * 0.3 + np.random.randn(n_samples) * 0.2
    y = np.digitize(signal, bins=[-0.3, 0.3])  # 3 clases: 0, 1, 2
    
    # Crear secuencias temporales
    X_sequences = []
    y_sequences = []
    
    for i in range(sequence_length, len(X)):
        X_sequences.append(X[i-sequence_length:i])
        y_sequences.append(y[i])
    
    X_sequences = np.array(X_sequences)
    y_sequences = np.array(y_sequences)
    
    # Split
    split_idx = int(len(X_sequences) * 0.7)
    val_split_idx = int(len(X_sequences) * 0.85)
    
    X_train = X_sequences[:split_idx]
    y_train = y_sequences[:split_idx]
    X_val = X_sequences[split_idx:val_split_idx]
    y_val = y_sequences[split_idx:val_split_idx]
    
    logger.info(f"📊 Datos: Train={len(X_train)}, Val={len(X_val)}")
    logger.info(f"📊 Shape: {X_train.shape}, Clases: {np.unique(y_train)}")
    
    # Construir modelo LSTM optimizado
    model = tf.keras.Sequential([
        # 🛡️ CONFIGURACIÓN ANTI-OVERFITTING MÁXIMA
        tf.keras.layers.LSTM(24, return_sequences=True, input_shape=(sequence_length, n_features),
                            dropout=0.8, recurrent_dropout=0.6,
                            kernel_regularizer=tf.keras.regularizers.l2(0.1),
                            recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
        tf.keras.layers.BatchNormalization(),
        
        tf.keras.layers.LSTM(12, return_sequences=False,
                            dropout=0.8, recurrent_dropout=0.6,
                            kernel_regularizer=tf.keras.regularizers.l2(0.1),
                            recurrent_regularizer=tf.keras.regularizers.l2(0.05)),
        tf.keras.layers.BatchNormalization(),
        
        tf.keras.layers.Dense(8, activation='relu',
                             kernel_regularizer=tf.keras.regularizers.l2(0.1)),
        tf.keras.layers.Dropout(0.7),
        
        tf.keras.layers.Dense(4, activation='relu',
                             kernel_regularizer=tf.keras.regularizers.l2(0.1)),
        tf.keras.layers.Dropout(0.6),
        
        tf.keras.layers.Dense(3, activation='softmax')
    ])
    
    # Optimizador conservador
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # Callbacks agresivos
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,              # 🔽 MUY BAJO
            restore_best_weights=True,
            min_delta=0.002         # 🔼 MAYOR MEJORA REQUERIDA
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.2,             # 🔽 REDUCCIÓN DRÁSTICA
            patience=3,             # 🔽 IMPACIENTE
            min_lr=0.000001
        )
    ]
    
    logger.info("🧪 Entrenando LSTM Regime optimizado...")
    
    # Entrenar modelo
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=30,               # 🔽 POCAS ÉPOCAS
        batch_size=12,           # 🔽 BATCH PEQUEÑO
        callbacks=callbacks,
        verbose=1
    )
    
    # Calcular overfitting
    train_loss = min(history.history['loss'])
    val_loss = min(history.history['val_loss'])
    overfitting_gap = abs(train_loss - val_loss)
    
    train_acc = max(history.history['accuracy'])
    val_acc = max(history.history['val_accuracy'])
    
    logger.info(f"\n📊 RESULTADOS LSTM REGIME OPTIMIZADO:")
    logger.info(f"  Train Loss: {train_loss:.4f}")
    logger.info(f"  Val Loss: {val_loss:.4f}")
    logger.info(f"  Overfitting Gap: {overfitting_gap:.4f}")
    logger.info(f"  Train Accuracy: {train_acc:.1%}")
    logger.info(f"  Val Accuracy: {val_acc:.1%}")
    logger.info(f"  Épocas entrenadas: {len(history.history['loss'])}")
    
    # Verificación target
    target_value = 0.18
    previous_gap = 0.295
    
    if overfitting_gap <= 0.20:
        if overfitting_gap <= target_value:
            status = "🎯 TARGET PERFECTO ALCANZADO"
        else:
            status = "✅ RANGO ÓPTIMO"
        logger.info(f"  ✅ {status}")
    else:
        status = "❌ REQUIERE MÁS OPTIMIZACIÓN"
        logger.warning(f"  ❌ {status}")
    
    # Comparación
    improvement = previous_gap - overfitting_gap
    improvement_pct = (improvement / previous_gap) * 100
    
    logger.info(f"\n📈 COMPARACIÓN:")
    logger.info(f"  Overfitting anterior: {previous_gap:.3f}")
    logger.info(f"  Overfitting actual: {overfitting_gap:.3f}")
    logger.info(f"  Mejora: {improvement:.3f} ({improvement_pct:.1f}%)")
    
    return overfitting_gap <= 0.20

if __name__ == "__main__":
    success = test_lstm_regime_optimization()
    
    if success:
        logger.info("\n✅ OPTIMIZACIÓN LSTM EXITOSA")
        logger.info("🎯 Regime LSTM optimizado para target overfitting ≤0.18")
    else:
        logger.warning("\n⚠️ REQUIERE AJUSTES ADICIONALES")
```

---

## **🚀 INSTRUCCIONES DE IMPLEMENTACIÓN GITHUB**

### **📋 COMMIT STRATEGY:**

```bash
# 1. Crear rama específica
git checkout -b fix-lstm-regime-overfitting

# 2. Aplicar cambios
git add config/training_config.yaml
git add src/models/regularized_models.py
git add scripts/fix_lstm_regime_overfitting.py

# 3. Commit específico
git commit -m "🎯 Fix LSTM Regime overfitting: 0.295 → 0.18

LSTM-specific optimizations:
- Increase dropout: 0.5→0.8, recurrent_dropout: 0.3→0.6
- Reduce LSTM units: 50→24→12 (much smaller)
- Increase L2 regularization: 0.01→0.1 
- Aggressive early stopping: patience 15→5
- Reduce epochs: 100→30, batch_size: 32→12
- Lower learning rate: 0.001→0.0003

Target: LSTM overfitting gap ≤ 0.18"

# 4. Test antes de push
python scripts/fix_lstm_regime_overfitting.py

# 5. Push si test exitoso
git push origin fix-lstm-regime-overfitting
```

### **✅ VALIDACIÓN ESPERADA:**

```
🎯 TARGET PERFECTO ALCANZADO
✅ Overfitting Gap: 0.17X ≤ 0.18
📈 Mejora: 0.12X (42.3%)
```

### **⚠️ SI NO FUNCIONA:**

Aplicar configuración aún más agresiva:
- `dropout_rate: 0.9` (máximo)
- `lstm_units: 16, 8` (aún más pequeño)
- `epochs: 20` (súper pocas)
- `patience: 3` (máximo agresivo)

**¿Listo para aplicar estos cambios específicos para LSTM?** 🎯