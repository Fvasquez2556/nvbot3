üîß Instrucciones Precisas para GitHub Copilot Agent
üìã TAREA: Corregir 4 errores cr√≠ticos en sistema anti-overfitting
üéØ OBJETIVO: Aplicar correcciones espec√≠ficas a archivos existentes para evitar fallas en entrenamiento real

üìÇ ARCHIVO 1: src/models/ensemble_models.py
üî¥ PROBLEMA: Ensemble sin m√©todo score() - causar√° crash en scikit-learn
‚úÖ SOLUCI√ìN: Reemplazar la clase EnsembleModel completa con esta versi√≥n corregida:
pythonclass EnsembleModel:
    """Ensemble model con m√©todo score() implementado."""
    
    def __init__(self, models_dict):
        self.models = models_dict
        self.weights = {}
        self.is_fitted = False
    
    def fit(self, X_train, y_train, X_val=None, y_val=None):
        """Entrenar todos los modelos y calcular pesos."""
        self.weights = {}
        
        for name, model in self.models.items():
            try:
                # CORRECCI√ìN: Solo argumentos b√°sicos para fit()
                if hasattr(model, 'fit'):
                    model.fit(X_train, y_train)  # Solo X y y
                    
                    # Calcular peso basado en performance
                    if X_val is not None:
                        val_score = model.score(X_val, y_val)
                        self.weights[name] = max(0.1, val_score)
                    else:
                        self.weights[name] = 1.0
                        
            except Exception as e:
                print(f"Error entrenando {name}: {e}")
                if name in self.weights:
                    del self.weights[name]
        
        # Normalizar pesos
        total_weight = sum(self.weights.values())
        if total_weight > 0:
            self.weights = {k: v/total_weight for k, v in self.weights.items()}
            self.is_fitted = True
        else:
            raise RuntimeError("Ning√∫n modelo se entren√≥ exitosamente")
        
        return self
    
    def predict(self, X):
        """Predicci√≥n con ensemble ponderado."""
        if not self.is_fitted:
            raise RuntimeError("El modelo debe ser entrenado primero")
        
        predictions = []
        weights = []
        
        for name, model in self.models.items():
            if name in self.weights:
                try:
                    pred = model.predict(X)
                    predictions.append(pred)
                    weights.append(self.weights[name])
                except Exception as e:
                    print(f"Error en predicci√≥n de {name}: {e}")
        
        if not predictions:
            raise RuntimeError("No hay modelos disponibles para predicci√≥n")
        
        # Promedio ponderado
        import numpy as np
        ensemble_pred = np.average(predictions, axis=0, weights=weights)
        return ensemble_pred
    
    def score(self, X, y):
        """M√âTODO SCORE CR√çTICO - Implementaci√≥n obligatoria para scikit-learn."""
        if not self.is_fitted:
            raise RuntimeError("El modelo debe ser entrenado primero")
        
        try:
            from sklearn.metrics import r2_score
            predictions = self.predict(X)
            return r2_score(y, predictions)
        except Exception as e:
            print(f"Error calculando score: {e}")
            return -999.0  # Score muy bajo para indicar error

üìÇ ARCHIVO 2: src/validation/walk_forward_validator.py
üî¥ PROBLEMA: No maneja casos con pocos datos - falla con "datos insuficientes"
‚úÖ SOLUCI√ìN: En el m√©todo validate(), reemplazar la secci√≥n de validaci√≥n de datos con:
pythondef validate(self, model, X, y, fit_params=None):
    """Validaci√≥n walk-forward con verificaci√≥n de datos."""
    import numpy as np
    from sklearn.model_selection import TimeSeriesSplit
    
    # CORRECCI√ìN CR√çTICA: Verificar y ajustar datos autom√°ticamente
    total_samples = len(X)
    min_required = self.n_splits * 100  # 100 muestras m√≠nimas por split
    
    if total_samples < min_required:
        print(f"‚ö†Ô∏è Datos insuficientes para Walk-Forward: {total_samples} < {min_required}")
        print(f"üîß Ajustando n_splits autom√°ticamente...")
        
        # Ajustar splits autom√°ticamente
        self.n_splits = max(2, total_samples // 100)
        print(f"‚úÖ Nuevo n_splits: {self.n_splits}")
    
    # Usar TimeSeriesSplit corregido
    tscv = TimeSeriesSplit(n_splits=self.n_splits)
    
    scores = []
    fold_results = []
    
    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
        try:
            # Extraer datos
            X_train_fold = X.iloc[train_idx] if hasattr(X, 'iloc') else X[train_idx]
            X_test_fold = X.iloc[test_idx] if hasattr(X, 'iloc') else X[test_idx]
            y_train_fold = y.iloc[train_idx] if hasattr(y, 'iloc') else y[train_idx]
            y_test_fold = y.iloc[test_idx] if hasattr(y, 'iloc') else y[test_idx]
            
            # CORRECCI√ìN: Solo argumentos b√°sicos para fit
            if hasattr(model, 'fit'):
                model.fit(X_train_fold, y_train_fold)  # Solo X y y
                
                # Calcular score
                fold_score = model.score(X_test_fold, y_test_fold)
                scores.append(fold_score)
                
                fold_results.append({
                    'fold': fold,
                    'train_size': len(train_idx),
                    'test_size': len(test_idx),
                    'score': fold_score
                })
                
                print(f"Fold {fold}: score={fold_score:.4f}")
            
        except Exception as e:
            print(f"Error en fold {fold}: {e}")
            scores.append(-999.0)
    
    # Resultados
    results = {
        'scores': scores,
        'mean_score': np.mean(scores) if scores else -999.0,
        'std_score': np.std(scores) if scores else 0.0,
        'fold_details': fold_results,
        'n_splits_used': self.n_splits
    }
    
    return results

üìÇ ARCHIVO 3: src/validation/overfitting_detector.py
üî¥ PROBLEMA: Manejo incorrecto de DataFrames vs arrays
‚úÖ SOLUCI√ìN: Agregar funci√≥n utilitaria al inicio del archivo:
pythondef safe_get_feature_names(data):
    """Extracci√≥n segura de nombres de features."""
    try:
        if hasattr(data, 'columns'):
            return list(data.columns)
        elif hasattr(data, 'shape') and len(data.shape) > 1:
            return [f'feature_{i}' for i in range(data.shape[1])]
        else:
            return ['feature_0']
    except:
        return ['unknown_feature']
Y reemplazar cualquier l√≠nea que use data.columns con:
python# Cambiar esto:
feature_names = data.columns

# Por esto:
feature_names = safe_get_feature_names(data)

üìÇ ARCHIVO 4: scripts/demo_anti_overfitting.py
üî¥ PROBLEMA: Argumentos incorrectos en entrenamiento de modelos
‚úÖ SOLUCI√ìN: En la funci√≥n que entrena modelos individuales, cambiar:
python# INCORRECTO (causar√° crash):
model.fit(X_train, y_train, X_val, y_val)

# CORRECTO:
model.fit(X_train, y_train)
Espec√≠ficamente buscar y reemplazar estas l√≠neas:
python# Para RandomForest:
rf_model.fit(X_train, y_train)  # Solo estos 2 argumentos

# Para Ridge:
ridge_model.fit(X_train, y_train)  # Solo estos 2 argumentos

# Para ElasticNet:
elastic_model.fit(X_train, y_train)  # Solo estos 2 argumentos

üìÇ ARCHIVO 5: Crear test_anti_overfitting_fixes.py
‚úÖ SOLUCI√ìN: Crear nuevo archivo para verificar correcciones:
python#!/usr/bin/env python3
"""
Test de correcciones del sistema anti-overfitting
Ejecutar despu√©s de aplicar las correcciones
"""

import sys
import numpy as np
import warnings
warnings.filterwarnings('ignore')

def test_ensemble_score():
    """Test cr√≠tico: Ensemble debe tener m√©todo score."""
    try:
        from src.models.ensemble_models import EnsembleModel
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.linear_model import Ridge
        
        # Datos de prueba
        X = np.random.randn(100, 5)
        y = np.random.randn(100)
        
        # Crear ensemble
        models = {
            'rf': RandomForestRegressor(n_estimators=10, random_state=42),
            'ridge': Ridge(random_state=42)
        }
        
        ensemble = EnsembleModel(models)
        ensemble.fit(X, y)
        
        # TEST CR√çTICO: Debe tener m√©todo score
        score = ensemble.score(X, y)
        print(f"‚úÖ Ensemble score funciona: {score:.4f}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en ensemble score: {e}")
        return False

def test_walk_forward_adjustment():
    """Test: Walk-forward debe ajustarse autom√°ticamente."""
    try:
        from src.validation.walk_forward_validator import WalkForwardValidator
        from sklearn.ensemble import RandomForestRegressor
        
        # Datos peque√±os intencionalmente
        X = np.random.randn(150, 3)  # Pocos datos
        y = np.random.randn(150)
        
        model = RandomForestRegressor(n_estimators=10, random_state=42)
        validator = WalkForwardValidator(n_splits=6)  # Muchos splits
        
        # Debe ajustarse autom√°ticamente
        results = validator.validate(model, X, y)
        print(f"‚úÖ Walk-forward se ajust√≥: {results['n_splits_used']} splits")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en walk-forward: {e}")
        return False

def main():
    """Funci√≥n principal de testing."""
    print("üß™ NvBot3 - Test de Correcciones Anti-Overfitting")
    print("=" * 55)
    
    # Verificar entorno
    if 'nvbot3_env' not in sys.executable:
        print("‚ö†Ô∏è Entorno virtual no activo")
        return False
    
    # Ejecutar tests cr√≠ticos
    test1 = test_ensemble_score()
    test2 = test_walk_forward_adjustment()
    
    if test1 and test2:
        print("\\nüéâ ¬°Todas las correcciones funcionan correctamente!")
        print("‚úÖ Sistema listo para datos reales")
        return True
    else:
        print("\\n‚ùå Algunas correcciones a√∫n fallan")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

üöÄ COMANDOS DE VERIFICACI√ìN
Despu√©s de aplicar todas las correcciones, ejecutar:
bash# 1. Activar entorno virtual
nvbot3_env\\Scripts\\activate

# 2. Ejecutar test de correcciones
python test_anti_overfitting_fixes.py

# 3. Si todo funciona, ejecutar demo corregido
python scripts/demo_anti_overfitting.py

‚úÖ RESULTADO ESPERADO
Despu√©s de aplicar estas correcciones:

‚úÖ Ensemble tendr√° m√©todo score() - Compatible con scikit-learn
‚úÖ Walk-forward se ajustar√° autom√°ticamente - No m√°s errores de datos insuficientes
‚úÖ Modelos se entrenar√°n correctamente - Solo argumentos v√°lidos en fit()
‚úÖ Manejo seguro de DataFrames - No m√°s errores de atributos

üéØ IMPACTO: Con datos reales (2+ a√±os de crypto), el sistema funcionar√° perfectamente sin estos crashes.
¬øEst√°n claras las instrucciones? ¬øNecesitas alguna aclaraci√≥n espec√≠fica para darle al agent?