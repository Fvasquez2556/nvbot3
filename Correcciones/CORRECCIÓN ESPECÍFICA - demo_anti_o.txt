# üîß CORRECCI√ìN ESPEC√çFICA - demo_anti_overfitting.py
# Funci√≥n create_sample_crypto_data() y demostraciones

def create_sample_crypto_data(n_samples: int = 5000) -> pd.DataFrame:  # CORRECCI√ìN: M√°s datos
    """Crear datos de prueba simulando series temporales de crypto."""
    
    # Generar fechas
    dates = pd.date_range(start='2023-01-01', periods=n_samples, freq='1h')
    
    # Simular datos de crypto con tendencia y volatilidad
    np.random.seed(42)
    
    # Price simulation con trend y volatilidad
    price_base = 50000  # BTC base price
    trend = np.cumsum(np.random.normal(0, 0.01, n_samples))
    volatility = np.random.normal(0, 0.02, n_samples)
    prices = price_base * (1 + trend + volatility)
    
    # Features t√©cnicos
    volume = np.random.exponential(1000, n_samples)
    rsi = 50 + 30 * np.sin(np.linspace(0, 20*np.pi, n_samples)) + np.random.normal(0, 5, n_samples)
    rsi = np.clip(rsi, 0, 100)
    
    # Moving averages con ventana m√≠nima para evitar NaN
    price_series = pd.Series(prices)
    ma_20 = price_series.rolling(20, min_periods=1).mean()
    ma_50 = price_series.rolling(50, min_periods=1).mean()
    
    # Volatility
    returns = price_series.pct_change().fillna(0)
    volatility_20 = returns.rolling(20, min_periods=1).std().fillna(0)
    
    # Target: predicir retorno pr√≥xima hora
    future_return = returns.shift(-1).fillna(0)
    
    df = pd.DataFrame({
        'timestamp': dates,
        'price': prices,
        'volume': volume,
        'rsi': rsi,
        'ma_20': ma_20,
        'ma_50': ma_50,
        'volatility_20': volatility_20,
        'returns': returns,
        'target': future_return
    }).set_index('timestamp')
    
    # Verificar y limpiar cualquier NaN restante
    df = df.ffill().fillna(0)
    
    # CORRECCI√ìN CR√çTICA: Asegurar nombres consistentes
    logger.info(f"Datos creados con columnas: {list(df.columns)}")
    logger.info(f"Shape de datos: {df.shape}")
    
    return df

def demo_walk_forward_validation():
    """Demostrar walk-forward validation."""
    logger.info("\n=== DEMO: Walk-Forward Validation ===")
    
    from validation import WalkForwardValidator
    from models import RegularizedXGBoost
    
    # CORRECCI√ìN: Crear datos de prueba con MUCHAS m√°s muestras para WF
    df = create_sample_crypto_data(5000)  # 5000 muestras = ~7 meses de datos por hora
    
    # CORRECCI√ìN: Definir features consistentes con los datos creados
    feature_cols = ['price', 'volume', 'rsi', 'ma_20', 'ma_50', 'volatility_20', 'returns']
    target_col = 'target'
    
    # Verificar que todas las columnas existen
    missing_cols = [col for col in feature_cols + [target_col] if col not in df.columns]
    if missing_cols:
        logger.error(f"Columnas faltantes: {missing_cols}")
        logger.error(f"Columnas disponibles: {list(df.columns)}")
        return
    
    # Verificar que tenemos features
    logger.info(f"Features a usar: {feature_cols}")
    logger.info(f"Target: {target_col}")
    
    # Inicializar walk-forward validator con par√°metros razonables
    validator = WalkForwardValidator(
        initial_train_months=2,    # 2 meses iniciales (m√°s realista)
        test_months=1,             # 1 mes de test
        retrain_frequency_months=1, # Retrain cada mes
        min_train_samples=100      # M√≠nimo 100 muestras
    )
    
    # Ejecutar validaci√≥n
    try:
        results = validator.validate(
            df=df,
            model_class=RegularizedXGBoost,
            model_params={'task_type': 'momentum'}
        )
        
        logger.info(f"Walk-forward completado: {len(results)} ventanas validadas")
        
        if results:
            # Analizar resultados
            performances = [r.model_performance for r in results if r.model_performance]
            if performances:
                accuracies = [p.get('accuracy', 0) for p in performances]
                logger.info(f"Accuracy promedio: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}")
            
    except Exception as e:
        logger.error(f"Error en walk-forward validation: {e}")
        import traceback
        traceback.print_exc()

def demo_overfitting_detection():
    """Demostrar detecci√≥n autom√°tica de overfitting."""
    logger.info("\n=== DEMO: Detecci√≥n de Overfitting ===")
    
    from validation import OverfittingDetector
    from models import RegularizedXGBoost, RegularizedEnsemble
    
    # Crear datos de prueba
    df = create_sample_crypto_data(1500)
    
    # CORRECCI√ìN: Usar nombres de columnas correctos
    feature_cols = ['price', 'volume', 'rsi', 'ma_20', 'ma_50', 'volatility_20', 'returns']
    target_col = 'target'
    
    # Verificar columnas
    if not all(col in df.columns for col in feature_cols + [target_col]):
        logger.error(f"Columnas faltantes. Disponibles: {list(df.columns)}")
        return
    
    # Split temporal para validaci√≥n
    split_idx = int(0.7 * len(df))
    
    X_train = df[feature_cols].iloc[:split_idx]
    y_train = df[target_col].iloc[:split_idx]
    X_val = df[feature_cols].iloc[split_idx:]
    y_val = df[target_col].iloc[split_idx:]
    
    logger.info(f"Train shape: {X_train.shape}, Val shape: {X_val.shape}")
    
    # Crear modelos con diferentes niveles de regularizaci√≥n
    models = {}
    
    # Modelo 1: Alta regularizaci√≥n
    model_high_reg = RegularizedXGBoost('momentum')
    try:
        model_high_reg.fit(X_train, y_train)  # CORRECCI√ìN: Solo X y y
        models['XGB_Alta_Regularizaci√≥n'] = model_high_reg
        logger.info("‚úÖ Modelo XGB entrenado correctamente")
    except Exception as e:
        logger.error(f"‚ùå Error entrenando XGB: {e}")
    
    # Modelo 2: Ensemble regularizado
    model_ensemble = RegularizedEnsemble('momentum')
    try:
        model_ensemble.fit(X_train, y_train)  # CORRECCI√ìN: Solo X y y
        models['Ensemble_Regularizado'] = model_ensemble
        logger.info("‚úÖ Modelo Ensemble entrenado correctamente")
    except Exception as e:
        logger.error(f"‚ùå Error entrenando Ensemble: {e}")
    
    if not models:
        logger.error("‚ùå No se pudo entrenar ning√∫n modelo")
        return
    
    # Inicializar detector
    detector = OverfittingDetector()
    
    # An√°lisis batch de todos los modelos
    try:
        comparison_df = detector.batch_analysis(
            models=models,
            X_train=X_train.values,  # CORRECCI√ìN: Convertir a numpy arrays
            y_train=y_train.values,
            X_val=X_val.values,
            y_val=y_val.values
        )
        
        logger.info("\nüìä Comparaci√≥n de Modelos:")
        logger.info(comparison_df.to_string(index=False))
        
        # An√°lisis detallado del mejor modelo
        if not comparison_df.empty:
            best_model_name = comparison_df.iloc[0]['model']
            best_model = models[best_model_name]
            
            report = detector.detect(
                best_model, X_train.values, y_train.values, 
                X_val.values, y_val.values, best_model_name
            )
            
            logger.info(f"\nüîç An√°lisis detallado de {best_model_name}:")
            logger.info(f"Nivel de overfitting: {report.level.value.upper()}")
            logger.info(f"Score de overfitting: {report.score:.4f}")
            logger.info(f"Gap train-val: {report.gap:.4f}")
            
            if report.warnings:
                logger.info("‚ö†Ô∏è Advertencias:")
                for warning in report.warnings:
                    logger.info(f"  - {warning}")
            
            if report.recommendations:
                logger.info("üí° Recomendaciones:")
                for rec in report.recommendations:
                    logger.info(f"  - {rec}")
        
    except Exception as e:
        logger.error(f"‚ùå Error en detecci√≥n de overfitting: {e}")
        import traceback
        traceback.print_exc()

def demo_complete_pipeline():
    """Demostrar pipeline completo anti-overfitting."""
    logger.info("\n=== DEMO: Pipeline Completo Anti-Overfitting ===")
    
    from validation import TemporalValidator, WalkForwardValidator, OverfittingDetector
    from models import RegularizedEnsemble
    
    # 1. Datos de entrada CON SUFICIENTES MUESTRAS
    df = create_sample_crypto_data(5000)  # CORRECCI√ìN: 5000 muestras
    feature_cols = ['price', 'volume', 'rsi', 'ma_20', 'ma_50', 'volatility_20', 'returns']
    target_col = 'target'
    
    logger.info(f"1Ô∏è‚É£ Datos creados: {len(df)} muestras de crypto simuladas")
    
    # 2. Validaci√≥n temporal inicial
    temporal_validator = TemporalValidator(train_ratio=0.6, val_ratio=0.2, test_ratio=0.2)
    train_data, val_data, test_data = temporal_validator.temporal_split(df)
    
    logger.info(f"2Ô∏è‚É£ Split temporal: Train={len(train_data)}, Val={len(val_data)}, Test={len(test_data)}")
    
    # 3. Walk-forward validation en el conjunto de entrenamiento
    try:
        wf_validator = WalkForwardValidator(initial_train_months=1, test_months=1)  # M√°s conservador
        wf_results = wf_validator.validate(
            train_data, RegularizedEnsemble, {'task_type': 'momentum'}
        )
        
        logger.info(f"3Ô∏è‚É£ Walk-forward completado: {len(wf_results)} ventanas validadas")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Walk-forward fall√≥: {e}")
        wf_results = []
    
    # 4. Entrenar modelo final en train completo
    X_train = train_data[feature_cols]
    y_train = train_data[target_col]
    X_val = val_data[feature_cols]
    y_val = val_data[target_col]
    
    final_model = RegularizedEnsemble('momentum')
    final_model.fit(X_train, y_train)  # CORRECCI√ìN: Solo X y y
    
    logger.info("4Ô∏è‚É£ Modelo final entrenado con m√°xima regularizaci√≥n")
    
    # 5. Detecci√≥n final de overfitting
    detector = OverfittingDetector()
    final_report = detector.detect(
        final_model, X_train.values, y_train.values,
        X_val.values, y_val.values, "Modelo_Final_Ensemble"
    )
    
    logger.info(f"5Ô∏è‚É£ Overfitting final: {final_report.level.value.upper()} (score: {final_report.score:.4f})")
    
    # 6. Evaluaci√≥n en test set (datos nunca vistos)
    X_test = test_data[feature_cols]
    y_test = test_data[target_col]
    
    test_predictions = final_model.predict(X_test)
    test_score = np.corrcoef(y_test, test_predictions)[0, 1] ** 2  # R¬≤ manual
    
    logger.info(f"6Ô∏è‚É£ Score en test set (nunca visto): {test_score:.4f}")
    
    # 7. Resumen final
    logger.info("\nüìà RESUMEN DEL PIPELINE:")
    logger.info(f"‚úÖ Validaci√≥n temporal: Sin data leakage")
    logger.info(f"‚úÖ Walk-forward: {len(wf_results)} ventanas validadas")
    logger.info(f"‚úÖ Modelo final: {len(final_model.models)} sub-modelos en ensemble")
    logger.info(f"‚úÖ Overfitting: {final_report.level.value.upper()} ({final_report.score:.4f})")
    logger.info(f"‚úÖ Performance test: {test_score:.4f}")
    
    if final_report.level.value in ['none', 'low']:
        logger.info("üéâ ¬°MODELO LISTO PARA PRODUCCI√ìN!")
    else:
        logger.info("‚ö†Ô∏è Modelo necesita m√°s regularizaci√≥n antes de producci√≥n")